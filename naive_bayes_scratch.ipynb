{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6630bed",
   "metadata": {},
   "source": [
    "# b2210765024 İlbey GÜLMEZ AIN313 Assignment 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "853df90d",
   "metadata": {},
   "source": [
    "Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8df9750",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "362f608f",
   "metadata": {},
   "source": [
    "## Part I "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd36eefc",
   "metadata": {},
   "source": [
    "## Maximum Likelihood Estimate (MLE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dabd92a",
   "metadata": {},
   "source": [
    "### Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7746a1a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLE for getting heads : 0.6\n"
     ]
    }
   ],
   "source": [
    "coin_flips = ['H','T','H','T','H']\n",
    "\n",
    "probability_heads = coin_flips.count('H') / len(coin_flips)\n",
    "\n",
    "print(\"MLE for getting heads :\", probability_heads)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670fcfab",
   "metadata": {},
   "source": [
    "### Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a54bf01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLE for the mean : 3.3333333333333335\n"
     ]
    }
   ],
   "source": [
    "candy_prices = np.array([2,3,5])\n",
    "mean_candy_prices = np.mean(candy_prices)\n",
    "print(\"MLE for the mean :\", mean_candy_prices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c84dadaf",
   "metadata": {},
   "source": [
    "### Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c028c86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLE for θ is 0.5\n"
     ]
    }
   ],
   "source": [
    "observations = [3,0,2,1,3,2,1,0,2,1]\n",
    "# Since 0 <= θ <= 1, probability of occurences of 0 and 1 gives us the MLE for θ.\n",
    "mle_theta = (observations.count(0) + observations.count(1)) / len(observations)\n",
    "print(\"MLE for θ is\", mle_theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb0b4d9",
   "metadata": {},
   "source": [
    "### Question 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98dc9d6a",
   "metadata": {},
   "source": [
    "In an uniform distribution, MLE of θ is the maximum observed value. So max value of X is the MLE of the sample."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaccd383",
   "metadata": {},
   "source": [
    "## Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b1482ce",
   "metadata": {},
   "source": [
    "From the data:\n",
    "\n",
    "P(Credit = Yes) = 5/10 = 0.5\n",
    "\n",
    "Now, let's calculate the conditional probabilities for the attributes:\n",
    "\n",
    "Sex:\n",
    "\n",
    "P(Sex = Male | Credit = Yes) = 3/4 = 0.75\n",
    "\n",
    "Education:\n",
    "\n",
    "P(Education = University | Credit = Yes) = 2/4 = 0.5\n",
    "\n",
    "Age:\n",
    "\n",
    "P(Age = 16-25 | Credit = Yes) = 0/3 = 0\n",
    "\n",
    "Let's apply Laplace Smoothing:\n",
    "\n",
    "0 + 1 / 3 + number of attributes (6)\n",
    "= 1/9\n",
    "\n",
    "Income:\n",
    "\n",
    "P(Income = Working Class | Credit = Yes) = 2/4 = 0.5\n",
    "\n",
    "Now, let's calculate the probability for a 23-year-old male university graduate working class customer to get credit:\n",
    "\n",
    "P(Credit = Yes | Male, University, 16-25, Working Class) = P(Credit = Yes) * P(Sex = Male | Credit = Yes) * P(Education = University | Credit = Yes) * P(Age = 16-25 | Credit = Yes) * P(Income = Working Class | Credit = Yes)\n",
    "\n",
    "P(Credit = Yes | Male, University, 16-25, Working Class) = 0.5 * 0.75 * 0.5 * 1/9 * 0.5 = 0.0104"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "836d67e9",
   "metadata": {},
   "source": [
    "## Part II: Semantic Segmentation of Multispectral Images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0abf79f4",
   "metadata": {},
   "source": [
    "### Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd9f0ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = np.load('classes.npy')\n",
    "train_data = np.load('train_data.npy')\n",
    "train_labels = np.load('train_labels.npy')\n",
    "train_masks = np.load('train_mask.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11fd9de2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0. Other Class/Image Border 1. Road Markings, Asphalt, Landing Pad 2. Water 3. Building 4. Vehicle (Car, Truck, or Bus) 5. Person 6. Vegetation 7. Wood Panel 8. Rocks, Sand 9. Chair, Table\n"
     ]
    }
   ],
   "source": [
    "print(*classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbec5f16",
   "metadata": {},
   "source": [
    "### Mask the data and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e00197d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data[train_masks != 0]\n",
    "train_labels = train_labels[train_masks != 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e140638",
   "metadata": {},
   "source": [
    "### Split the image into train and test splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56f6f950",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    train_data,\n",
    "    train_labels,\n",
    "    test_size=0.2,\n",
    "    random_state = 123\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a5824b",
   "metadata": {},
   "source": [
    "### Implement Naive Bayes Classification and accuracy functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0167119f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mean_variance_prior(X_train, y_train):\n",
    "    unique_labels = np.unique(y_train)\n",
    "    parameters = {}\n",
    "    for label in unique_labels:\n",
    "        X_train_class = X_train[y_train == label]\n",
    "        parameters[label] = {\n",
    "            \"mean\": X_train_class.mean(axis = 0),\n",
    "            \"variance\": X_train_class.var(axis = 0),\n",
    "            \"prior\": X_train_class.shape[0] / X_train.shape[0]\n",
    "        }\n",
    "    return parameters\n",
    "\n",
    "def gaussian_probability(X,mean,variance):\n",
    "    exponent = -0.5 * np.sum(np.log(2. * np.pi * variance))\n",
    "    exponent -= 0.5 * np.sum(((X - mean) ** 2) / (2 * variance), 1)\n",
    "    return exponent\n",
    "    \n",
    "def naive_bayes_classification(X_test,y_train,parameters):\n",
    "    predicted_labels = {}\n",
    "    probabilities = np.zeros((X_test.shape[0], len(np.unique(y_train))))\n",
    "    for class_, parameter in parameters.items():\n",
    "        PX_y = gaussian_probability(X_test,parameter[\"mean\"][0],parameter[\"variance\"][0])\n",
    "        probabilities[: , class_] = PX_y + np.log(parameter['prior'])\n",
    "        predicted_labels = np.unique(y_train)[np.argmax(probabilities, axis=1)]\n",
    "    return predicted_labels\n",
    "\n",
    "def calculate_accuracy(predicted_labels,test_labels):\n",
    "    return (predicted_labels == test_labels).sum() / len(test_labels)\n",
    "\n",
    "def train_evaluate(X_train,X_test,y_train,y_test):\n",
    "    parameters = calculate_mean_variance_prior(X_train, y_train)\n",
    "    predicted_labels = naive_bayes_classification(X_test,y_train,parameters)\n",
    "    return calculate_accuracy(predicted_labels, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19987021",
   "metadata": {},
   "source": [
    "### Calculate accuracy for RGB layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6574e4ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for RGB layers is :  0.611\n"
     ]
    }
   ],
   "source": [
    "rgb_accuracy = train_evaluate(X_train[:, :3], X_test[:, :3], y_train, y_test)\n",
    "\n",
    "print(f\"Accuracy for RGB layers is : {rgb_accuracy : .3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6687bd27",
   "metadata": {},
   "source": [
    "### Calculate accuracy for Infrared layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c80509f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Infrared layers is :  0.598\n"
     ]
    }
   ],
   "source": [
    "infrared_accuracy = train_evaluate(X_train[:, 3:], X_test[:, 3:],y_train,y_test)\n",
    "print(f\"Accuracy for Infrared layers is : {infrared_accuracy : .3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a294ea3",
   "metadata": {},
   "source": [
    "### Calculate accuracy for all layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f6557b5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for all layers is :  0.336\n"
     ]
    }
   ],
   "source": [
    "accuracy = train_evaluate(X_train,X_test,y_train,y_test)\n",
    "print(f\"Accuracy for all layers is : {accuracy : .3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77c1eb9",
   "metadata": {},
   "source": [
    "### Calculate accuracy for each layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "28ec8c72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for band 1 :  0.635\n",
      "Accuracy for band 2 :  0.530\n",
      "Accuracy for band 3 :  0.587\n",
      "Accuracy for band 4 :  0.587\n",
      "Accuracy for band 5 :  0.705\n",
      "Accuracy for band 6 :  0.726\n"
     ]
    }
   ],
   "source": [
    "for index in range(X_train.shape[-1]):\n",
    "    current_acc = train_evaluate(X_train[:, index : index + 1],\n",
    "                                 X_test[:, index : index + 1],y_train,y_test)\n",
    "    print(f\"Accuracy for band {index + 1} : {current_acc : .3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f352bb2e",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf206be6",
   "metadata": {},
   "source": [
    "In this assignment;\n",
    "\n",
    "Demonstrated MLE in diverse scenarios, establishing a foundation for subsequent applications.\n",
    "\n",
    "Successfully applied the classifier to individual spectral bands, RGB layers, Infrared layers, and the entire set of six spectral bands.\n",
    "\n",
    "Attained accuracies of 61.1% for RGB layers, 59.8% for Infrared layers, and 33.6% for all six bands, revealing varied performance. This variety might be caused by numerous reasons such as unbalanced data. But the key conclusion is that the layers yield relatively good accuracies when evaluated seperately but yield poor score when combined.\n",
    "\n",
    "Examined accuracy for each layer individually, highlighting distinctions in classification performance.\n",
    "\n",
    "In summary, this assignment demonstrated MLE calculations and implemented a Gaussian Naive Bayes classifier for the semantic segmentation of multispectral images using the RIT-18 dataset.\n",
    "\n",
    "\n",
    "#### Note:\n",
    "\n",
    "I personally learned:\n",
    "\n",
    "- How to load .npy files to python\n",
    "\n",
    "- MLE calculations\n",
    "\n",
    "- Semantic segmentation concept\n",
    "\n",
    "- Masking a data\n",
    "\n",
    "- Using log() on Gaussian Probability density function to prevent underflow and decrease runtime\n",
    "\n",
    "- Implementing Naive Bayes Classifier manually in Python"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
